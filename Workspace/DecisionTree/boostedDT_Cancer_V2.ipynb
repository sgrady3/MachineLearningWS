{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##breast cancer training dataset from GSE2034\n",
    "dataframe = pd.read_csv('data/filter_set_gcrma.csv',index_col=0)\t\n",
    "array = dataframe.values\n",
    "X= array[:,0:1246] ##1246 variable genes\n",
    "y=array[:,1311] ##labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##split data set into train and test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a base decision tree.\n",
    "clf = tree.DecisionTreeClassifier(class_weight=\"balanced\")\n",
    "clf_boosted = AdaBoostClassifier(base_estimator=clf,random_state = 7)\n",
    "clf_boosted.fit(X_train,y_train)\n",
    "y_pred=clf_boosted.predict(X_test)\n",
    "print(\"Accuracy: %.2f\"  % metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv('data/filter_set_gcrma_test.csv',index_col=0)\n",
    "array = dataframe.values\n",
    "X_test2= array[:,0:1246]\n",
    "y_test2=array[:,1246]\n",
    "y_pred2=clf_boosted.predict(X_test2)\n",
    "y_pred2_prob=clf_boosted.predict_proba(X_test2)\n",
    "print(\"Accuracy: %.2f\"  % metrics.accuracy_score(y_test2, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Print confusion matrix.\n",
    "## Contains True Positives (TP), True Negatives (TN), False Positives (FP), and False Negatives (FP)\t\n",
    "cfs = metrics.confusion_matrix(y_test2, y_pred2)\n",
    "print(cfs)\n",
    "TP = cfs[1, 1]\n",
    "TN = cfs[0, 0]\n",
    "FP = cfs[0, 1]\n",
    "FN = cfs[1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Get the recall, which is the TP/(TP+FN)\n",
    "print(\"Sensitivity: %.2f\"  % metrics.recall_score(y_test2, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the precision, which is the TP/(TP+FP)\n",
    "print(\"Precision: %.2f\"  % metrics.precision_score(y_test2, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the specificity, which is the TN/(TN+FP)\n",
    "specificity = float(TN) / float(TN + FP)\n",
    "print(\"Specificity: %.2f\"  % specificity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.roc_auc_score(y_test2, y_pred2_prob[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y_test2, y_pred2_prob[:,1])\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.title('ROC curve for cancer classifier')\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compare boosted decision tree's performance to decision tree's \n",
    "dataframe = pd.read_csv('data/filter_set_gcrma.csv',index_col=0)\t\n",
    "array = dataframe.values\n",
    "X= array[:,0:1246]\n",
    "y=array[:,1311]\t\n",
    "boosted_scores = []\n",
    "scores = []\n",
    "boosted_sense = []\n",
    "sense = []\n",
    "boosted_prec = []\n",
    "prec =[]\n",
    "train_size = np.arange(0.2,0.85,0.01)\n",
    "for i in train_size:\n",
    "\tX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=i, random_state=7)\n",
    "\tclf = tree.DecisionTreeClassifier(class_weight=\"balanced\")\n",
    "\tclf_boosted = AdaBoostClassifier(base_estimator=clf,random_state = 7)\n",
    "\tclf_boosted= clf_boosted.fit(X_train,y_train)\n",
    "\tpred = clf_boosted.predict(X_test)\n",
    "\tboosted_scores.append(metrics.accuracy_score(pred,y_test))\n",
    "\tboosted_sense.append(metrics.recall_score(pred,y_test))\n",
    "\tboosted_prec.append(metrics.precision_score(pred,y_test))\n",
    "\tclf = clf.fit(X_train,y_train)\n",
    "\tpred = clf.predict(X_test)\n",
    "\tscores.append(metrics.accuracy_score(pred,y_test))\n",
    "\tsense.append(metrics.recall_score(pred,y_test))\n",
    "\tprec.append(metrics.precision_score(pred,y_test))\n",
    "\t\n",
    "reg, = plt.plot(train_size,scores,\"-\",label=\"Decision Tree\")\n",
    "boost, = plt.plot(train_size,boosted_scores,\"-\",color=\"red\",label=\"Boosted\")\n",
    "plt.title('Decision Tree Performance:\\nVarying size of Training Data')\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(handles=[reg,boost])\n",
    "plt.show()\n",
    "\n",
    "reg, = plt.plot(train_size,sense,\"-\",label=\"Decision Tree\")\n",
    "boost, = plt.plot(train_size,boosted_sense,\"-\",color=\"red\",label=\"Boosted\")\n",
    "plt.title('Decision Tree Performance:\\nVarying size of Training Data')\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('Sensitivity')\n",
    "plt.legend(handles=[reg,boost])\n",
    "plt.show()\n",
    "\n",
    "reg, = plt.plot(train_size,prec,\"-\",label=\"Decision Tree\")\n",
    "boost, = plt.plot(train_size,boosted_prec,\"-\",color=\"red\",label=\"Boosted\")\n",
    "plt.title('Decision Tree Performance:\\nVarying size of Training Data')\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend(handles=[reg,boost])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
